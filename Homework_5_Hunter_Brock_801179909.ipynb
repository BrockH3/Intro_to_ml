{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUlPTXq+HHpCXYr52yNFB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrockH3/Intro_to_ml/blob/main/Homework_5_Hunter_Brock_801179909.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "AMRq3UT1Wonx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf5e390-05d9-4028-f8ed-dcf5bc08a85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#temp data put into tensor\n",
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)\n",
        "\n",
        "t_un = t_u * 0.1\n",
        "\n",
        "#create model\n",
        "def model(t_u, w2, w1, b):\n",
        "  return w2*(t_u**2) + w1*t_u + b\n",
        "\n",
        "#create loss function based\n",
        "def loss_function(t_p,t_c):\n",
        "  squared_diff = (t_p-t_c)**2\n",
        "  return squared_diff.mean()"
      ],
      "metadata": {
        "id": "VI2JEjG8YWXM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the data and return parameters\n",
        "def train_loop(epochs, optimizer, params, t_u, t_c):\n",
        "  for epoch in range(1, epochs+1):\n",
        "\n",
        "    t_p = model(t_u, *params)           #input data into model for each iteration\n",
        "    loss = loss_function(t_p, t_c)      #get loss for this iteration\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()                    #deals with learning rate and updates parameters\n",
        "\n",
        "    if (epoch % 500 == 0):\n",
        "      print('epoch: ', epoch, ' loss: ', float(loss))    #display epochs and loss every 500 iterations\n",
        "  return params\n"
      ],
      "metadata": {
        "id": "YONn42tWZeSb"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD optimizer for #1 for different learning rates .1 to .0001\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "learning_rate = .1\n",
        "epochs = 5000\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "train_loop(epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c)"
      ],
      "metadata": {
        "id": "26jqaEvaiBvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec1e413-ddb5-42ee-80c0-0f2bf6e9e665"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  nan\n",
            "epoch:  1000  loss:  nan\n",
            "epoch:  1500  loss:  nan\n",
            "epoch:  2000  loss:  nan\n",
            "epoch:  2500  loss:  nan\n",
            "epoch:  3000  loss:  nan\n",
            "epoch:  3500  loss:  nan\n",
            "epoch:  4000  loss:  nan\n",
            "epoch:  4500  loss:  nan\n",
            "epoch:  5000  loss:  nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, nan, nan], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "train_loop(epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c)"
      ],
      "metadata": {
        "id": "31FAbxr-Z1N6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "796c65c2-209a-4b3a-b570-2f43ee08878e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  nan\n",
            "epoch:  1000  loss:  nan\n",
            "epoch:  1500  loss:  nan\n",
            "epoch:  2000  loss:  nan\n",
            "epoch:  2500  loss:  nan\n",
            "epoch:  3000  loss:  nan\n",
            "epoch:  3500  loss:  nan\n",
            "epoch:  4000  loss:  nan\n",
            "epoch:  4500  loss:  nan\n",
            "epoch:  5000  loss:  nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, nan, nan], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "train_loop(epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c)"
      ],
      "metadata": {
        "id": "y11tjHy1m39N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28ed0da-a315-46a0-8cc0-057decc70631"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  nan\n",
            "epoch:  1000  loss:  nan\n",
            "epoch:  1500  loss:  nan\n",
            "epoch:  2000  loss:  nan\n",
            "epoch:  2500  loss:  nan\n",
            "epoch:  3000  loss:  nan\n",
            "epoch:  3500  loss:  nan\n",
            "epoch:  4000  loss:  nan\n",
            "epoch:  4500  loss:  nan\n",
            "epoch:  5000  loss:  nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, nan, nan], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "train_loop(epochs, optimizer, params, t_un, t_c)"
      ],
      "metadata": {
        "id": "n6shoRkXm4nT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b03713-43b3-44af-beef-196c9e2c53ef"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  10.708596229553223\n",
            "epoch:  1000  loss:  8.642083168029785\n",
            "epoch:  1500  loss:  7.1710052490234375\n",
            "epoch:  2000  loss:  6.123478412628174\n",
            "epoch:  2500  loss:  5.377227306365967\n",
            "epoch:  3000  loss:  4.8452863693237305\n",
            "epoch:  3500  loss:  4.465787887573242\n",
            "epoch:  4000  loss:  4.194724082946777\n",
            "epoch:  4500  loss:  4.0008015632629395\n",
            "epoch:  5000  loss:  3.8617441654205322\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5570, -0.8881, -0.8753], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam optimizer for #1 for different learning rates .1 to .0001\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "learning_rate = 0.1\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "train_loop(epochs, optimizer, params, t_un, t_c)\n"
      ],
      "metadata": {
        "id": "51q8X2Fkm-S2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd96335-71a4-4a90-ccc6-0c6c8d3e0845"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  675.7943725585938\n",
            "epoch:  1000  loss:  675.7943725585938\n",
            "epoch:  1500  loss:  675.7943725585938\n",
            "epoch:  2000  loss:  675.7943725585938\n",
            "epoch:  2500  loss:  675.7943725585938\n",
            "epoch:  3000  loss:  675.7943725585938\n",
            "epoch:  3500  loss:  675.7943725585938\n",
            "epoch:  4000  loss:  675.7943725585938\n",
            "epoch:  4500  loss:  675.7943725585938\n",
            "epoch:  5000  loss:  675.7943725585938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "train_loop(epochs, optimizer, params, t_un, t_c)"
      ],
      "metadata": {
        "id": "WvkXvM2lm-kO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3e90ae-1187-4624-f544-de947fd6015a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  6.111171245574951\n",
            "epoch:  1000  loss:  3.936777353286743\n",
            "epoch:  1500  loss:  3.1178040504455566\n",
            "epoch:  2000  loss:  2.93183970451355\n",
            "epoch:  2500  loss:  2.871260404586792\n",
            "epoch:  3000  loss:  2.8129384517669678\n",
            "epoch:  3500  loss:  2.7440876960754395\n",
            "epoch:  4000  loss:  2.664673328399658\n",
            "epoch:  4500  loss:  2.5763673782348633\n",
            "epoch:  5000  loss:  2.4824559688568115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.4673,  0.4768, -5.6706], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "train_loop(epochs, optimizer, params, t_un, t_c)"
      ],
      "metadata": {
        "id": "YWeRwzgSm-xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcc563d-a564-42c0-cfa5-72526098bbce"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  103.7950210571289\n",
            "epoch:  1000  loss:  13.018479347229004\n",
            "epoch:  1500  loss:  8.064860343933105\n",
            "epoch:  2000  loss:  7.688989639282227\n",
            "epoch:  2500  loss:  7.295182704925537\n",
            "epoch:  3000  loss:  6.830938816070557\n",
            "epoch:  3500  loss:  6.30617094039917\n",
            "epoch:  4000  loss:  5.739596843719482\n",
            "epoch:  4500  loss:  5.159209728240967\n",
            "epoch:  5000  loss:  4.600074291229248\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.4484, -0.0524, -1.7755], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "train_loop(epochs, optimizer, params, t_un, t_c)"
      ],
      "metadata": {
        "id": "atRhtc5Im-8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff45bca-e0bf-40c8-a3ee-07b688a53b07"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  loss:  578.252685546875\n",
            "epoch:  1000  loss:  491.2365417480469\n",
            "epoch:  1500  loss:  413.86767578125\n",
            "epoch:  2000  loss:  345.2539367675781\n",
            "epoch:  2500  loss:  284.667236328125\n",
            "epoch:  3000  loss:  231.51058959960938\n",
            "epoch:  3500  loss:  185.28330993652344\n",
            "epoch:  4000  loss:  145.5520782470703\n",
            "epoch:  4500  loss:  111.92162322998047\n",
            "epoch:  5000  loss:  84.00926971435547\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5721,  0.5698, -0.4337], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "url='/content/drive/My Drive/Intro to ML/datasets/Housing.csv'\n",
        "housing=pd.DataFrame(pd.read_csv(url))\n",
        "\n",
        "# set up housing_1 for problem 2 and housing for problem 3\n",
        "variables =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "#defining map function to change yes to 1 and no to 0\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0,})\n",
        "\n",
        "housing[variables] = housing[variables].apply(binary_map)         #applying it to variable list\n",
        "housing = housing.drop(columns = 'furnishingstatus')              #housing holds all values in csv file\n",
        "\n",
        "#scale all inputs to be between 1 and 0\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']\n",
        "\n",
        "housing[num_vars] = scaler.fit_transform(housing[num_vars])\n",
        "\n",
        "housing_1 = housing.drop(columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea'])   #removes variables for part a"
      ],
      "metadata": {
        "id": "vAJ9FopSntSx"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_1c = torch.from_numpy(housing_1.pop('price').to_numpy())\n",
        "housing_1u = torch.from_numpy(housing_1.to_numpy())\n"
      ],
      "metadata": {
        "id": "pwne_KhPpPd4"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomize training set and validation set for housing set\n",
        "\n",
        "n = housing_1u.shape[0]\n",
        "n_val = int(0.2 * n)\n",
        "\n",
        "shuffled = torch.randperm(n)      # randomizes number of samples\n",
        "\n",
        "train_set = shuffled[:-n_val]     #selects samples to be in training and validation set\n",
        "val_set = shuffled[-n_val:]\n",
        "\n",
        "#set training input and output\n",
        "train_t_u = housing_1u[train_set]\n",
        "train_t_c = housing_1c[train_set]\n",
        "val_t_u = housing_1u[val_set]\n",
        "val_t_c = housing_1c[val_set]\n"
      ],
      "metadata": {
        "id": "pU0KqiXa8dmp"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w1, w2, w3, w4, w5, b):\n",
        "  return t_u[:,0]*w1 + t_u[:,1]*w2+t_u[:,2]*w3 +t_u[:,3]*w4 +t_u[:,4]*w5 + b\n",
        "\n",
        "def training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      train_t_p = model(train_t_u, *params)\n",
        "      train_loss = loss_function(train_t_p, train_t_c)\n",
        "\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_function(val_t_p, val_t_c)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (epoch % 500 == 0):\n",
        "        print('epoch: ', epoch, ' training loss: ', float(train_loss), ' validation loss: ', float(val_loss))\n",
        "  return params"
      ],
      "metadata": {
        "id": "QJ10D_St7Aa2"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD of different learning rates\n",
        "learning_rate = .1\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "id": "x2gFT6JXDfVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c20348-fd38-4fce-f135-237e00efeea5"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.01216399693659933  validation loss:  0.009804423994532931\n",
            "epoch:  1000  training loss:  0.011926406126370609  validation loss:  0.009788448986840139\n",
            "epoch:  1500  training loss:  0.011913569447518528  validation loss:  0.009857502851582493\n",
            "epoch:  2000  training loss:  0.011912704040246736  validation loss:  0.009880714028597302\n",
            "epoch:  2500  training loss:  0.011912644039822303  validation loss:  0.009887275795472647\n",
            "epoch:  3000  training loss:  0.011912639865595874  validation loss:  0.009889054074883927\n",
            "epoch:  3500  training loss:  0.011912639574261473  validation loss:  0.009889525855795651\n",
            "epoch:  4000  training loss:  0.01191263955417597  validation loss:  0.0098896647833627\n",
            "epoch:  4500  training loss:  0.011912639552937103  validation loss:  0.00988969289670902\n",
            "epoch:  5000  training loss:  0.011912639552846877  validation loss:  0.009889697709695031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4398, 0.0430, 0.3135, 0.1416, 0.0992, 0.0470], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .01\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsqEj60Ga9jW",
        "outputId": "e9062103-ec32-4214-84a0-fdda52061757"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.050077905235839756  validation loss:  0.0444278891339675\n",
            "epoch:  1000  training loss:  0.022705957631735645  validation loss:  0.01929503035535647\n",
            "epoch:  1500  training loss:  0.01621904152422177  validation loss:  0.013445839752805928\n",
            "epoch:  2000  training loss:  0.014234647248741641  validation loss:  0.011652632039129376\n",
            "epoch:  2500  training loss:  0.013379904841847652  validation loss:  0.010865381755972525\n",
            "epoch:  3000  training loss:  0.01290269737917822  validation loss:  0.010424102650705406\n",
            "epoch:  3500  training loss:  0.012600348613473825  validation loss:  0.010151514528635767\n",
            "epoch:  4000  training loss:  0.012398415766796116  validation loss:  0.009979185004962515\n",
            "epoch:  4500  training loss:  0.012260099695575254  validation loss:  0.00987098688301423\n",
            "epoch:  5000  training loss:  0.012163809605967324  validation loss:  0.009804772758066101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4746, 0.1557, 0.2985, 0.1148, 0.0850, 0.0055], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEc-6gx5a9ru",
        "outputId": "20178f58-f8d7-4c00-cb1a-1a3dcf3564db"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.22467949422299668  validation loss:  0.1956993634209742\n",
            "epoch:  1000  training loss:  0.13979077141779214  validation loss:  0.1248285309347878\n",
            "epoch:  1500  training loss:  0.11825044876507586  validation loss:  0.10720231871399102\n",
            "epoch:  2000  training loss:  0.10314105487230595  validation loss:  0.09368666278694648\n",
            "epoch:  2500  training loss:  0.09045900043144295  validation loss:  0.0819749387080227\n",
            "epoch:  3000  training loss:  0.0796476391349563  validation loss:  0.0719134618096965\n",
            "epoch:  3500  training loss:  0.07041616715675156  validation loss:  0.06331570925814718\n",
            "epoch:  4000  training loss:  0.0625290240191471  validation loss:  0.05597892800968023\n",
            "epoch:  4500  training loss:  0.055786598650370035  validation loss:  0.04971831388364087\n",
            "epoch:  5000  training loss:  0.05001911829418469  validation loss:  0.04437371952336568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.6943,  0.5513,  0.6511,  0.3395,  0.3751, -0.3894],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .0001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4CWfvi8a9zy",
        "outputId": "b3825455-0932-490d-a26a-b50c1dbe26a6"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.9894570224970614  validation loss:  0.9063217022372597\n",
            "epoch:  1000  training loss:  0.7920378493434947  validation loss:  0.7197616951777881\n",
            "epoch:  1500  training loss:  0.6414149214506142  validation loss:  0.5782221257829351\n",
            "epoch:  2000  training loss:  0.5263709755579196  validation loss:  0.47080456646004776\n",
            "epoch:  2500  training loss:  0.4383785459185016  validation loss:  0.38923830040486956\n",
            "epoch:  3000  training loss:  0.37095644464705024  validation loss:  0.3272496102168162\n",
            "epoch:  3500  training loss:  0.31917817633376827  validation loss:  0.28008045287758804\n",
            "epoch:  4000  training loss:  0.2792988936924693  validation loss:  0.24412333303812275\n",
            "epoch:  4500  training loss:  0.24847221432335917  validation loss:  0.2166442802721516\n",
            "epoch:  5000  training loss:  0.2245347618427258  validation loss:  0.19557230471359957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.8455,  0.7548,  0.9047,  0.7714,  0.7960, -0.5087],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADAM optimizer at different learning rates\n",
        "learning_rate = .1\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F8W47MxbApt",
        "outputId": "33ea7b78-21bd-45d2-9cf2-35e4463e2a30"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.011912639552202935  validation loss:  0.00988969887448344\n",
            "epoch:  1000  training loss:  0.011912639552202873  validation loss:  0.009889698656484501\n",
            "epoch:  1500  training loss:  0.011912639552202873  validation loss:  0.009889698680525569\n",
            "epoch:  2000  training loss:  0.011912639552202873  validation loss:  0.009889698613964546\n",
            "epoch:  2500  training loss:  0.01191263955220289  validation loss:  0.009889698569580663\n",
            "epoch:  3000  training loss:  0.011912639552202885  validation loss:  0.009889698538111337\n",
            "epoch:  3500  training loss:  0.011912639552202878  validation loss:  0.009889698470560189\n",
            "epoch:  4000  training loss:  0.01191263955220287  validation loss:  0.009889698492769057\n",
            "epoch:  4500  training loss:  0.011912639552202925  validation loss:  0.00988969851581795\n",
            "epoch:  5000  training loss:  0.011912639552665794  validation loss:  0.009889700618850413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4398, 0.0429, 0.3135, 0.1416, 0.0992, 0.0470], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .01\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIKbXZulbAtN",
        "outputId": "72d72b38-3260-4bb8-c726-98e0e5c17b4b"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.013986067494196733  validation loss:  0.010536977867337217\n",
            "epoch:  1000  training loss:  0.012089790644432104  validation loss:  0.009630667664796717\n",
            "epoch:  1500  training loss:  0.011917123896192938  validation loss:  0.009822971442256781\n",
            "epoch:  2000  training loss:  0.011912665413109765  validation loss:  0.00988429142490441\n",
            "epoch:  2500  training loss:  0.011912639575357143  validation loss:  0.009889536715550687\n",
            "epoch:  3000  training loss:  0.011912639552219478  validation loss:  0.009889698706587485\n",
            "epoch:  3500  training loss:  0.011912639552210991  validation loss:  0.009889699315664918\n",
            "epoch:  4000  training loss:  0.011912639552208035  validation loss:  0.009889699156107084\n",
            "epoch:  4500  training loss:  0.011912639552205668  validation loss:  0.009889699071294798\n",
            "epoch:  5000  training loss:  0.011912639552204405  validation loss:  0.009889698999668144\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4398, 0.0429, 0.3135, 0.1416, 0.0992, 0.0470], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41kMV0h6bAxE",
        "outputId": "5aa74d9d-ed92-4204-87d2-396975650a7f"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.1296562585947208  validation loss:  0.11189332049322566\n",
            "epoch:  1000  training loss:  0.05247657415274395  validation loss:  0.04695816826310343\n",
            "epoch:  1500  training loss:  0.03530491736055161  validation loss:  0.030755731180898763\n",
            "epoch:  2000  training loss:  0.024094047340914443  validation loss:  0.01982748418310336\n",
            "epoch:  2500  training loss:  0.018158909058461323  validation loss:  0.014155131442001813\n",
            "epoch:  3000  training loss:  0.01546685960170203  validation loss:  0.01171265088325336\n",
            "epoch:  3500  training loss:  0.01417278041225573  validation loss:  0.010670822397547118\n",
            "epoch:  4000  training loss:  0.013357096867347614  validation loss:  0.010121873872603543\n",
            "epoch:  4500  training loss:  0.012759533003543289  validation loss:  0.009798247348892413\n",
            "epoch:  5000  training loss:  0.012343747272449697  validation loss:  0.009644760669550542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.4590,  0.2004,  0.2660,  0.1183,  0.0930, -0.0091],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .0001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6nuZbivbA0l",
        "outputId": "01403249-531f-4c1a-ec4d-ca97815291f3"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  1.014760264243401  validation loss:  0.9321986895427541\n",
            "epoch:  1000  training loss:  0.8166621731817465  validation loss:  0.746174813037206\n",
            "epoch:  1500  training loss:  0.6496696742825423  validation loss:  0.5898999093674097\n",
            "epoch:  2000  training loss:  0.5101705657592381  validation loss:  0.45990308909703\n",
            "epoch:  2500  training loss:  0.39514661734458467  validation loss:  0.3532778272994209\n",
            "epoch:  3000  training loss:  0.301994782323875  validation loss:  0.26750867434798403\n",
            "epoch:  3500  training loss:  0.2283617489054255  validation loss:  0.20031058052017084\n",
            "epoch:  4000  training loss:  0.17198982171318503  validation loss:  0.14947900800890174\n",
            "epoch:  4500  training loss:  0.13058060081122316  validation loss:  0.11275707190382626\n",
            "epoch:  5000  training loss:  0.10168190220607395  validation loss:  0.08772602641662566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.6140,  0.6137,  0.5912,  0.5955,  0.5945, -0.3708],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# problem 3\n",
        "housing_c = torch.from_numpy(housing.pop('price').to_numpy())\n",
        "housing_u = torch.from_numpy(housing.to_numpy())\n"
      ],
      "metadata": {
        "id": "zuBTEU4PdX3T"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomize training set and validation set for housing set\n",
        "n = housing_u.shape[0]\n",
        "n_val = int(0.2 * n)\n",
        "\n",
        "shuffled = torch.randperm(n)      # randomizes number of samples\n",
        "\n",
        "train_set = shuffled[:-n_val]     #selects samples to be in training and validation set\n",
        "val_set = shuffled[-n_val:]\n",
        "\n",
        "#set training input and output\n",
        "train_t_u = housing_u[train_set]\n",
        "train_t_c = housing_c[train_set]\n",
        "val_t_u = housing_u[val_set]\n",
        "val_t_c = housing_c[val_set]\n",
        "\n",
        "train_t_un = train_t_u *.1\n",
        "val_t_un = val_t_u *.1"
      ],
      "metadata": {
        "id": "WjVZbVcJdX7O"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#could be done easier with loop, but brute force works\n",
        "def model(t_u, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, w11, b):\n",
        "  return t_u[:,0]*w1 + t_u[:,1]*w2+t_u[:,2]*w3 + t_u[:,3]*w4 +t_u[:,4]*w5 + t_u[:,5]*w6 + t_u[:,6]*w7 + t_u[:,7]*w8 + t_u[:,8]*w9 + t_u[:,9]*w10 + t_u[:,10]*w11 + b"
      ],
      "metadata": {
        "id": "QBYQ_Kz0dYA0"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD of different learning rates for full housing set\n",
        "learning_rate = .1\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_un, train_t_c, val_t_un, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD0IMnEzfvLt",
        "outputId": "c5e0d4cb-62ad-4006-976e-eef3f828c77f"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.011040567088121725  validation loss:  0.014867711363510379\n",
            "epoch:  1000  training loss:  0.01022680553242207  validation loss:  0.01414091889170381\n",
            "epoch:  1500  training loss:  0.009734907918568974  validation loss:  0.013745842892276332\n",
            "epoch:  2000  training loss:  0.009427164545950948  validation loss:  0.013526753450090126\n",
            "epoch:  2500  training loss:  0.009225761371145563  validation loss:  0.013399360879724756\n",
            "epoch:  3000  training loss:  0.009086591484625647  validation loss:  0.013318585706381105\n",
            "epoch:  3500  training loss:  0.008984533476683019  validation loss:  0.013260704265027417\n",
            "epoch:  4000  training loss:  0.008905200511198716  validation loss:  0.013213557874225165\n",
            "epoch:  4500  training loss:  0.008840255759796738  validation loss:  0.013171088083802308\n",
            "epoch:  5000  training loss:  0.008784833944273993  validation loss:  0.013130501114159917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.2630,  1.0078,  1.3604,  1.2365,  0.6591,  0.4930,  0.3278,  0.9397,\n",
              "         0.8674,  0.9550,  0.5993, -0.0022], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .01\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_un, train_t_c, val_t_un, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rilwrCwEfvO7",
        "outputId": "a4e02092-ae54-4d5f-9ce1-518114289fec"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.01224370336405396  validation loss:  0.01603414499766936\n",
            "epoch:  1000  training loss:  0.012079262256882523  validation loss:  0.015870299343844974\n",
            "epoch:  1500  training loss:  0.01192350387380403  validation loss:  0.01571618819546969\n",
            "epoch:  2000  training loss:  0.011775951561850049  validation loss:  0.015571272433651268\n",
            "epoch:  2500  training loss:  0.0116361250260781  validation loss:  0.015434989665685558\n",
            "epoch:  3000  training loss:  0.011503599319465551  validation loss:  0.01530681513038805\n",
            "epoch:  3500  training loss:  0.01137799299760829  validation loss:  0.015186285322761351\n",
            "epoch:  4000  training loss:  0.011258921285786268  validation loss:  0.01507296444235641\n",
            "epoch:  4500  training loss:  0.011146025447748668  validation loss:  0.014966394396250979\n",
            "epoch:  5000  training loss:  0.011038949233816481  validation loss:  0.014866185861831653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0180,  0.9989,  1.0361,  1.0384,  0.9275,  0.8796,  0.8150,  0.9938,\n",
              "         0.9639,  0.9839,  0.8927, -0.0442], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_un, train_t_c, val_t_un, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NflX38ggfvS1",
        "outputId": "a73f26e4-e7a2-4a88-cdcf-d5a658bed811"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.012887350091195366  validation loss:  0.01653944391835686\n",
            "epoch:  1000  training loss:  0.012445671758538814  validation loss:  0.016185547388709448\n",
            "epoch:  1500  training loss:  0.012372363053551624  validation loss:  0.01614444700853344\n",
            "epoch:  2000  training loss:  0.012347523366336351  validation loss:  0.016131368501994685\n",
            "epoch:  2500  training loss:  0.012329160826526783  validation loss:  0.016117283174603893\n",
            "epoch:  3000  training loss:  0.012311720829170059  validation loss:  0.016101363081513432\n",
            "epoch:  3500  training loss:  0.012294475557342577  validation loss:  0.016084637729669535\n",
            "epoch:  4000  training loss:  0.012277368494809312  validation loss:  0.01606771142398076\n",
            "epoch:  4500  training loss:  0.012260329748940924  validation loss:  0.016050744164448502\n",
            "epoch:  5000  training loss:  0.012243386697440403  validation loss:  0.016033856512470402\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0003,  0.9977,  1.0030,  1.0026,  0.9874,  0.9856,  0.9772,  0.9992,\n",
              "         0.9942,  0.9969,  0.9865, -0.0582], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .0001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_un, train_t_c, val_t_un, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TiXfpTLfvWm",
        "outputId": "b66d28a6-5429-42e7-f3cc-45711b36da63"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  6.597136951110534  validation loss:  7.185690268947099\n",
            "epoch:  1000  training loss:  4.2099933580260345  validation loss:  4.647785669761401\n",
            "epoch:  1500  training loss:  2.7567464230353504  validation loss:  3.0890840202636984\n",
            "epoch:  2000  training loss:  1.8695869618526253  validation loss:  2.1271164482307032\n",
            "epoch:  2500  training loss:  1.325669494139165  validation loss:  1.5293653821976292\n",
            "epoch:  3000  training loss:  0.9899644546919759  validation loss:  1.1543492611850867\n",
            "epoch:  3500  training loss:  0.7806518663137243  validation loss:  0.915894736777572\n",
            "epoch:  4000  training loss:  0.64814831710939  validation loss:  0.7614480114365834\n",
            "epoch:  4500  training loss:  0.5624044343343463  validation loss:  0.6589107467565896\n",
            "epoch:  5000  training loss:  0.5052051403851441  validation loss:  0.58863949578761\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7050,  0.5467,  0.8341,  0.6233,  0.0317,  0.6341,  0.4472,  0.9074,\n",
              "         0.4789,  0.6540,  0.5862, -1.0051], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam optimizer for whole housing set\n",
        "learning_rate = .1\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2FXI2TcfvaG",
        "outputId": "94ac949e-cbf9-465e-af54-a32d066fca02"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.00872775056875363  validation loss:  0.00799863893759057\n",
            "epoch:  1000  training loss:  0.008724858143265636  validation loss:  0.008003510886943592\n",
            "epoch:  1500  training loss:  0.008724858143229895  validation loss:  0.008003511527688623\n",
            "epoch:  2000  training loss:  0.008724858143229174  validation loss:  0.008003511696211486\n",
            "epoch:  2500  training loss:  0.008724858143229174  validation loss:  0.008003511686902737\n",
            "epoch:  3000  training loss:  0.008724858143228936  validation loss:  0.008003511653855678\n",
            "epoch:  3500  training loss:  0.008724858143228908  validation loss:  0.008003511768469359\n",
            "epoch:  4000  training loss:  0.008724858143228847  validation loss:  0.00800351176924287\n",
            "epoch:  4500  training loss:  0.00872485814322881  validation loss:  0.008003511823150351\n",
            "epoch:  5000  training loss:  0.008724858143229377  validation loss:  0.008003511757207132\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3131,  0.0523,  0.2782,  0.1135,  0.0426,  0.0216,  0.0288,  0.0812,\n",
              "         0.0811,  0.0772,  0.0526, -0.0012], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .01\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDGxc2Dzfvd0",
        "outputId": "78ac0765-acce-49cc-e73e-64b2981e4675"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  0.02464301683848217  validation loss:  0.02239770264400653\n",
            "epoch:  1000  training loss:  0.013297240301805492  validation loss:  0.011853687049693317\n",
            "epoch:  1500  training loss:  0.010132960250737002  validation loss:  0.009139660868146333\n",
            "epoch:  2000  training loss:  0.009104598456302076  validation loss:  0.008272227755033232\n",
            "epoch:  2500  training loss:  0.008795693127079634  validation loss:  0.008032158048102358\n",
            "epoch:  3000  training loss:  0.008732642927661094  validation loss:  0.007998328058603644\n",
            "epoch:  3500  training loss:  0.008725289853343036  validation loss:  0.008000992260788943\n",
            "epoch:  4000  training loss:  0.008724868035792787  validation loss:  0.00800307929862982\n",
            "epoch:  4500  training loss:  0.008724858214933268  validation loss:  0.008003474007888185\n",
            "epoch:  5000  training loss:  0.008724858143365438  validation loss:  0.008003509828639127\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3131,  0.0523,  0.2782,  0.1135,  0.0426,  0.0216,  0.0288,  0.0812,\n",
              "         0.0811,  0.0772,  0.0526, -0.0012], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I01qSx2Gfvhc",
        "outputId": "93f89f28-1df3-4c5b-9762-d32a62bb1566"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  2.0271089456902778  validation loss:  2.2501947689076274\n",
            "epoch:  1000  training loss:  0.25321783531429976  validation loss:  0.3017479367467424\n",
            "epoch:  1500  training loss:  0.08094298447700614  validation loss:  0.092934125491925\n",
            "epoch:  2000  training loss:  0.057774618019641615  validation loss:  0.06185785680559454\n",
            "epoch:  2500  training loss:  0.04313954090751599  validation loss:  0.04375883910153407\n",
            "epoch:  3000  training loss:  0.0330796563830743  validation loss:  0.03180574553505266\n",
            "epoch:  3500  training loss:  0.02640096609053869  validation loss:  0.024327761105885536\n",
            "epoch:  4000  training loss:  0.02179199312423444  validation loss:  0.019578618095694385\n",
            "epoch:  4500  training loss:  0.018349936502134716  validation loss:  0.016313362530696124\n",
            "epoch:  5000  training loss:  0.015644463915868087  validation loss:  0.013889892411295056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3423,  0.3976,  0.1818,  0.1112,  0.2341,  0.0151,  0.0507,  0.0872,\n",
              "         0.0817,  0.0662,  0.0283, -0.3134], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = .0001\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad = True)\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_housing(epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZU_Sxk7fvky",
        "outputId": "378c38e5-586d-4f33-d1e9-29065cbc6d73"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  500  training loss:  9.15089882088412  validation loss:  9.870549057333644\n",
            "epoch:  1000  training loss:  7.917530361349346  validation loss:  8.55730489210452\n",
            "epoch:  1500  training loss:  6.805249020740085  validation loss:  7.3716709904048905\n",
            "epoch:  2000  training loss:  5.803533217289066  validation loss:  6.302560037159572\n",
            "epoch:  2500  training loss:  4.903823681281888  validation loss:  5.340955495035946\n",
            "epoch:  3000  training loss:  4.099164391516155  validation loss:  4.479536204153597\n",
            "epoch:  3500  training loss:  3.383839237780325  validation loss:  3.7122951790791454\n",
            "epoch:  4000  training loss:  2.753028548187354  validation loss:  3.0341788379621515\n",
            "epoch:  4500  training loss:  2.202503523239358  validation loss:  2.4407675838519385\n",
            "epoch:  5000  training loss:  1.728340133004364  validation loss:  1.9279759945695223\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5627,  0.5635,  0.5602,  0.5617,  0.5630,  0.5562,  0.5582,  0.5604,\n",
              "         0.5591,  0.5606,  0.5575, -0.4351], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    }
  ]
}